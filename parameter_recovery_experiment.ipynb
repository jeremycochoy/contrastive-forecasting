{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA Parameter Recovery Experiment\n",
    "\n",
    "This notebook trains a linear head to recover ARMA model parameters from the trained SimpleModel's latent representations.\n",
    "\n",
    "## Overview\n",
    "- Load the pre-trained SimpleModel from forecast_arma.ipynb\n",
    "- Create a linear head that outputs 2 tensors of 8 floats (AR and MA parameters)\n",
    "- Train the head to recover the original ARMA parameters\n",
    "- Evaluate performance during and after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Import functions from codebase modules\n",
    "from arma import generate_arma_batch\n",
    "from network import SimpleModel\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION: ARMA Parameter Recovery Settings\n# =============================================================================\nNUM_ARMA_PARAMS = 4  # Number of AR and MA coefficients to recover (matches dimension=4 in training)\n# =============================================================================\nprint(f\"Configuration: NUM_ARMA_PARAMS = {NUM_ARMA_PARAMS}\")\nprint(\"Change NUM_ARMA_PARAMS in this cell to control the number of AR/MA coefficients to recover\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the pre-trained model\nmodel = SimpleModel(C=4, H=1024, W=32, num_layers=12)\nmodel.load_state_dict(torch.load('trained_simple_model_H1024.pth', map_location=device))\nmodel = model.to(device)\nmodel.eval()  # Set to evaluation mode\nprint(\"Pre-trained model loaded successfully\")\n\n# Freeze the pre-trained model parameters\nfor param in model.parameters():\n    param.requires_grad = False\nprint(\"Pre-trained model parameters frozen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ParameterRecoveryHead(nn.Module):\n    \"\"\"Linear head to recover ARMA parameters from latent representations.\n    Works per-channel on H dimension: [B*C, T, H] -> [B*C, T, num_arma_params]\"\"\"\n    \n    def __init__(self, H=64, hidden_dim=64, num_arma_params=8):\n        super().__init__()\n        input_dim = H\n        \n        self.shared_layers = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.CELU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.CELU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.CELU(),\n            nn.Dropout(0.1),\n        )\n        \n        # Separate heads for AR and MA parameters\n        self.ar_head = nn.Linear(hidden_dim, num_arma_params)\n        self.ma_head = nn.Linear(hidden_dim, num_arma_params)\n        \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape [B*C, T, H]\n        Returns:\n            ar_params: AR parameters [B*C, T, num_arma_params]\n            ma_params: MA parameters [B*C, T, num_arma_params]\n        \"\"\"\n        shared_features = self.shared_layers(x)\n        ar_predictions = torch.tanh(self.ar_head(shared_features))\n        ma_predictions = torch.tanh(self.ma_head(shared_features))\n        return ar_predictions, ma_predictions\n\n# Initialize the parameter recovery head\n# Each channel has its own ARMA process, so the head works per-channel on H=1024\nMODEL_H = 1024\nparam_head = ParameterRecoveryHead(H=MODEL_H, hidden_dim=256, num_arma_params=NUM_ARMA_PARAMS).to(device)\nprint(f\"Parameter recovery head initialized with input_dim={MODEL_H}, num_params={NUM_ARMA_PARAMS}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_latent_features(model, x):\n    \"\"\"Extract latent features from the pre-trained model, per-channel.\"\"\"\n    with torch.no_grad():\n        h_hat, h = model(x)\n        # h shape: [B, T, C, H]\n        B, T, C, H = h.shape\n        # Reshape to [B*C, T, H] so each channel is treated independently\n        h_reshaped = h.permute(0, 2, 1, 3).reshape(B * C, T, H)\n        return h_reshaped\n\ndef parameter_loss(pred_ar, pred_ma, true_ar, true_ma):\n    \"\"\"Compute loss between predicted and true parameters.\n    \n    Args:\n        pred_ar: [B*C, T, NUM_ARMA_PARAMS] - predicted AR parameters\n        pred_ma: [B*C, T, NUM_ARMA_PARAMS] - predicted MA parameters\n        true_ar: [B*C, NUM_ARMA_PARAMS] - true AR parameters\n        true_ma: [B*C, NUM_ARMA_PARAMS] - true MA parameters\n    \n    Returns:\n        total_loss: combined AR + MA loss\n        ar_loss: AR loss\n        ma_loss: MA loss\n    \"\"\"\n    # Average over time dimension to get [B*C, NUM_ARMA_PARAMS]\n    pred_ar_avg = pred_ar.mean(dim=1)\n    pred_ma_avg = pred_ma.mean(dim=1)\n    \n    ar_loss = F.mse_loss(pred_ar_avg, true_ar)\n    ma_loss = F.mse_loss(pred_ma_avg, true_ma)\n    \n    return ar_loss + ma_loss, ar_loss, ma_loss"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(batch_size=32, T_raw=4096, C=4, seed=None):\n",
    "    \"\"\"Generate training data with known ARMA parameters.\"\"\"\n",
    "    # Generate ARMA data with known parameters\n",
    "    x, parameters = generate_arma_batch(batch_size=batch_size, T_raw=T_raw, C=C, seed=seed)\n",
    "    x = x.to(device)\n",
    "    \n",
    "    # Extract true parameters\n",
    "    true_ar_params = []\n",
    "    true_ma_params = []\n",
    "    \n",
    "    for ar_poly, ma_poly in parameters:\n",
    "        # Convert polynomial form to parameter form\n",
    "        # AR: 1 - φ1*L - φ2*L^2 - ... -> [φ1, φ2, ...]\n",
    "        # MA: 1 + θ1*L + θ2*L^2 + ... -> [θ1, θ2, ...]\n",
    "        ar_coeffs = -ar_poly[1:]  # Remove constant term and negate\n",
    "        ma_coeffs = ma_poly[1:]   # Remove constant term\n",
    "        \n",
    "        # Pad or truncate to exactly NUM_ARMA_PARAMS parameters\n",
    "        ar_padded = np.pad(ar_coeffs, (0, max(0, NUM_ARMA_PARAMS - len(ar_coeffs))), mode='constant')[:NUM_ARMA_PARAMS]\n",
    "        ma_padded = np.pad(ma_coeffs, (0, max(0, NUM_ARMA_PARAMS - len(ma_coeffs))), mode='constant')[:NUM_ARMA_PARAMS]\n",
    "        \n",
    "        true_ar_params.append(ar_padded)\n",
    "        true_ma_params.append(ma_padded)\n",
    "    \n",
    "    true_ar = torch.tensor(np.array(true_ar_params), dtype=torch.float32).to(device)\n",
    "    true_ma = torch.tensor(np.array(true_ma_params), dtype=torch.float32).to(device)\n",
    "    \n",
    "    return x, true_ar, true_ma\n",
    "\n",
    "# Test data generation\n",
    "x_test, ar_test, ma_test = prepare_training_data(batch_size=4, seed=42)\n",
    "print(f\"Test data shapes: x={x_test.shape}, ar={ar_test.shape}, ma={ma_test.shape}\")\n",
    "print(f\"Sample AR params: {ar_test[0]}\")\n",
    "print(f\"Sample MA params: {ma_test[0]}\")\n",
    "print(f\"AR L1 norm: {torch.norm(ar_test[0], p=1):.4f}\")\n",
    "print(f\"MA L1 norm: {torch.norm(ma_test[0], p=1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training state — persists across cell re-runs\noptimizer = optim.Adam(param_head.parameters(), lr=1e-3)\ntrain_losses = []\nval_losses = []\nar_losses = []\nma_losses = []\ncurrent_epoch = 0\n\n# Fixed validation set\nx_val, ar_val, ma_val = prepare_training_data(batch_size=32, seed=0)\nh_val = extract_latent_features(model, x_val)\n\ndef train_parameter_recovery(num_epochs=100, batch_size=32):\n    \"\"\"Train the parameter recovery head. Can be interrupted and re-run to continue.\"\"\"\n    global current_epoch\n    start = current_epoch\n    \n    for epoch in range(start, start + num_epochs):\n        # Training step\n        param_head.train()\n        optimizer.zero_grad()\n        \n        x_train, ar_train, ma_train = prepare_training_data(batch_size=batch_size, seed=epoch)\n        h_train = extract_latent_features(model, x_train)\n        \n        pred_ar, pred_ma = param_head(h_train)\n        loss, ar_loss, ma_loss = parameter_loss(pred_ar, pred_ma, ar_train, ma_train)\n        \n        loss.backward()\n        optimizer.step()\n        \n        # Validation step\n        param_head.eval()\n        with torch.no_grad():\n            pred_ar_val, pred_ma_val = param_head(h_val)\n            val_loss, _, _ = parameter_loss(pred_ar_val, pred_ma_val, ar_val, ma_val)\n        \n        train_losses.append(loss.item())\n        val_losses.append(val_loss.item())\n        ar_losses.append(ar_loss.item())\n        ma_losses.append(ma_loss.item())\n        current_epoch = epoch + 1\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch {epoch+1}: \"\n                  f\"Train Loss: {loss.item():.6f}, \"\n                  f\"Val Loss: {val_loss.item():.6f}, \"\n                  f\"AR Loss: {ar_loss.item():.6f}, \"\n                  f\"MA Loss: {ma_loss.item():.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run training — interrupt and re-run this cell to continue\ntrain_parameter_recovery(num_epochs=30_000, batch_size=32)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.8)\n",
    "plt.plot(val_losses, label='Val Loss', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(ar_losses, label='AR Loss', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('AR Parameter Loss')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(ma_losses, label='MA Loss', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MA Parameter Loss')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final performance\n",
    "def evaluate_parameter_recovery(param_head, model, num_samples=100):\n",
    "    \"\"\"Evaluate parameter recovery performance on test samples.\"\"\"\n",
    "    param_head.eval()\n",
    "    \n",
    "    all_ar_errors = []\n",
    "    all_ma_errors = []\n",
    "    all_total_errors = []\n",
    "    all_baseline_errors = []  # Error if predicting 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            try:\n",
    "                # Generate test sample\n",
    "                x_test, ar_true, ma_true = prepare_training_data(batch_size=1, seed=i+1000)\n",
    "                h_test = extract_latent_features(model, x_test)\n",
    "                \n",
    "                # Predict parameters: [B, T, NUM_ARMA_PARAMS]\n",
    "                pred_ar, pred_ma = param_head(h_test)\n",
    "                \n",
    "                # Compute errors using parameter_loss function\n",
    "                _, ar_error, ma_error = parameter_loss(pred_ar, pred_ma, ar_true, ma_true)\n",
    "                ar_error = ar_error.item()\n",
    "                ma_error = ma_error.item()\n",
    "                total_error = ar_error + ma_error\n",
    "                \n",
    "                # Compute baseline error (predicting 0)\n",
    "                baseline_ar_error = F.mse_loss(torch.zeros_like(ar_true), ar_true).item()\n",
    "                baseline_ma_error = F.mse_loss(torch.zeros_like(ma_true), ma_true).item()\n",
    "                baseline_total_error = baseline_ar_error + baseline_ma_error\n",
    "                \n",
    "                all_ar_errors.append(ar_error)\n",
    "                all_ma_errors.append(ma_error)\n",
    "                all_total_errors.append(total_error)\n",
    "                all_baseline_errors.append(baseline_total_error)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in sample {i}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if not all_ar_errors:\n",
    "        raise RuntimeError(\"No valid samples processed during evaluation\")\n",
    "    \n",
    "    return {\n",
    "        'ar_errors': all_ar_errors,\n",
    "        'ma_errors': all_ma_errors,\n",
    "        'total_errors': all_total_errors,\n",
    "        'baseline_errors': all_baseline_errors,\n",
    "        'mean_ar_error': np.mean(all_ar_errors),\n",
    "        'mean_ma_error': np.mean(all_ma_errors),\n",
    "        'mean_total_error': np.mean(all_total_errors),\n",
    "        'mean_baseline_error': np.mean(all_baseline_errors),\n",
    "        'std_ar_error': np.std(all_ar_errors),\n",
    "        'std_ma_error': np.std(all_ma_errors),\n",
    "        'std_total_error': np.std(all_total_errors),\n",
    "        'std_baseline_error': np.std(all_baseline_errors)\n",
    "    }\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_parameter_recovery(param_head, model, num_samples=200)\n",
    "\n",
    "print(\"\\n=== Parameter Recovery Performance ===\")\n",
    "print(f\"Mean AR Error: {results['mean_ar_error']:.6f} ± {results['std_ar_error']:.6f}\")\n",
    "print(f\"Mean MA Error: {results['mean_ma_error']:.6f} ± {results['std_ma_error']:.6f}\")\n",
    "print(f\"Mean Total Error: {results['mean_total_error']:.6f} ± {results['std_total_error']:.6f}\")\n",
    "print(f\"\\n=== Baseline (predicting 0) ===\")\n",
    "print(f\"Mean Baseline Error: {results['mean_baseline_error']:.6f} ± {results['std_baseline_error']:.6f}\")\n",
    "print(f\"Improvement Ratio: {results['mean_baseline_error'] / results['mean_total_error']:.2f}x better than baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter recovery quality\n",
    "def plot_parameter_comparison(param_head, model, num_examples=5):\n",
    "    \"\"\"Plot comparison between true and predicted parameters.\"\"\"\n",
    "    param_head.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_examples, 2, figsize=(12, 3*num_examples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_examples):\n",
    "            # Generate test sample\n",
    "            x_test, ar_true, ma_true = prepare_training_data(batch_size=1, seed=i+2000)\n",
    "            h_test = extract_latent_features(model, x_test)\n",
    "            \n",
    "            # Predict parameters: [1, T, NUM_ARMA_PARAMS]\n",
    "            pred_ar, pred_ma = param_head(h_test)\n",
    "            \n",
    "            # Average over T to get single [NUM_ARMA_PARAMS] prediction for plotting\n",
    "            pred_ar_mean = pred_ar[0].mean(dim=0).cpu().numpy()  # [NUM_ARMA_PARAMS]\n",
    "            pred_ma_mean = pred_ma[0].mean(dim=0).cpu().numpy()  # [NUM_ARMA_PARAMS]\n",
    "            \n",
    "            # Convert to numpy for plotting\n",
    "            ar_true_np = ar_true[0].cpu().numpy()\n",
    "            ma_true_np = ma_true[0].cpu().numpy()\n",
    "            ar_pred_np = pred_ar_mean\n",
    "            ma_pred_np = pred_ma_mean\n",
    "            \n",
    "            # Plot AR parameters\n",
    "            axes[i, 0].bar(range(NUM_ARMA_PARAMS), ar_true_np, alpha=0.7, label='True', color='blue')\n",
    "            axes[i, 0].bar(range(NUM_ARMA_PARAMS), ar_pred_np, alpha=0.7, label='Predicted', color='red')\n",
    "            axes[i, 0].set_title(f'AR Parameters - Sample {i+1}')\n",
    "            axes[i, 0].set_xlabel('Parameter Index')\n",
    "            axes[i, 0].set_ylabel('Value')\n",
    "            axes[i, 0].legend()\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot MA parameters\n",
    "            axes[i, 1].bar(range(NUM_ARMA_PARAMS), ma_true_np, alpha=0.7, label='True', color='blue')\n",
    "            axes[i, 1].bar(range(NUM_ARMA_PARAMS), ma_pred_np, alpha=0.7, label='Predicted', color='red')\n",
    "            axes[i, 1].set_title(f'MA Parameters - Sample {i+1}')\n",
    "            axes[i, 1].set_xlabel('Parameter Index')\n",
    "            axes[i, 1].set_ylabel('Value')\n",
    "            axes[i, 1].legend()\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot parameter comparisons\n",
    "plot_parameter_comparison(param_head, model, num_examples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(results['ar_errors'], bins=30, alpha=0.7, color='blue')\n",
    "plt.xlabel('AR Parameter MSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('AR Parameter Error Distribution')\n",
    "plt.axvline(results['mean_ar_error'], color='red', linestyle='--', label=f'Mean: {results[\"mean_ar_error\"]:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(results['ma_errors'], bins=30, alpha=0.7, color='green')\n",
    "plt.xlabel('MA Parameter MSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('MA Parameter Error Distribution')\n",
    "plt.axvline(results['mean_ma_error'], color='red', linestyle='--', label=f'Mean: {results[\"mean_ma_error\"]:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(results['total_errors'], bins=30, alpha=0.7, color='purple')\n",
    "plt.xlabel('Total Parameter MSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Total Parameter Error Distribution')\n",
    "plt.axvline(results['mean_total_error'], color='red', linestyle='--', label=f'Mean: {results[\"mean_total_error\"]:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save the trained parameter recovery head\ntorch.save(param_head.state_dict(), 'parameter_recovery_head.pth')\nprint(\"Parameter recovery head saved to 'parameter_recovery_head.pth'\")\n\n# Summary of results\nprint(f\"\\n=== Experiment Summary (epoch {current_epoch}) ===\")\nif train_losses:\n    print(f\"Final training loss: {train_losses[-1]:.6f}\")\n    print(f\"Final validation loss: {val_losses[-1]:.6f}\")\n\nif 'results' in locals() and results:\n    print(f\"Mean AR parameter recovery error: {results['mean_ar_error']:.6f}\")\n    print(f\"Mean MA parameter recovery error: {results['mean_ma_error']:.6f}\")\n    print(f\"Mean total parameter recovery error: {results['mean_total_error']:.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}